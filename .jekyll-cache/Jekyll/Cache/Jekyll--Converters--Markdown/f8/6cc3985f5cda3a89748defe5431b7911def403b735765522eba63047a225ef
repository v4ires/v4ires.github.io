I"‚2<h2 id="instala√ß√£o-do-apache-hadoop-28x-em-modo-multi-node">Instala√ß√£o do Apache Hadoop 2.8.x em modo Multi Node</h2>

<p>Requisitos iniciais:</p>

<ul>
  <li>1) Tenha o Java 7+ instalado</li>
  <li>2) Realize a configura√ß√£o em modo <a href="/config-hadoop-single-node/" target="_blank"><em>single node</em></a> para todas a m√°quinas desejadas</li>
  <li>3) Tenha o servidor SSH devidamente instalado e configurado</li>
  <li>4) Configure o SSH para o acesso sem senha com todos os endere√ßos de IP das m√°quinas desejadas incluindo o <em>localhost</em></li>
</ul>

<p>*ps: Este tutorial foi testado com o sistema operacional Ubuntu 16.04 e 14.04. Caso deseje configurar em uma vers√£o mais antiga, recente ou em outro SO, pequenas mudan√ßas podem ocorrer nos procedimentos apresentados.</p>

<h3 id="tldr">TL;DR</h3>

<p>O projeto Apache Hadoop √© um <em>software</em> de c√≥digo aberto mantido pela Apache Foundation que tem como prop√≥sito fornecer uma implementa√ß√£o de c√≥digo aberto do modelo de programa√ß√£o <em>MapReduce</em> de forma confi√°vel e escal√°vel. O Hadoop √© projetado para ampliar o processamento de um √∫nico servidor em milhares de m√°quinas, onde cada uma das m√°quinas oferecem poder de processamento e armazenamento local. Esta ferramenta √© utilizada para processamento em <em>batch</em> de grandes volumes de dados (<em>Big Data</em>). Atualmente, o Apache Hadoop √© uma das ferramentas mais conhecidas para processamento distribu√≠do, mas existem outras ferramentas similares que se integram ao Hadoop, como o <strong>Apache Spark</strong>, <strong>Apache Storm</strong> e dentre outros.</p>

<p>*para mais informa√ß√µes a respeito do Apache Hadoop acessem o site <a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p>

<h3 id="lets-get-started">Let‚Äôs get started</h3>

<p>Neste tutorial voc√™ ir√° aprender a configurar o Apache Hadoop no modo <em>Multi Node</em>. Montando um ambiente capaz de executar seus primeiros <em>scripts</em> em <em>MapReduce</em>.</p>

<p>Primeiramente configure todas as m√°quinas que deseja montar um cluster Hadoop no modo <em>single node</em>. Para configurar basta seguir as instru√ß√µes dispon√≠veis no seguinte <a href="/config-hadoop-single-node">link</a>.</p>

<p>Outro ponto importante √© a configura√ß√£o do ssh sem senha entre todas m√°quinas que voc√™ pretende montar o cluster, o que inclui ela mesma (<em>localhost</em>). Para realizar essa tarefa basta seguir as instru√ß√µes do tutorial disponibilizado no portal <a href="https://www.vivaolinux.com.br/dica/SSH-sem-senha/">Viva o Linux</a>.</p>

<p>Ap√≥s realizada essa primeira etapa fa√ßa as devidas modifica√ß√µes para que o Hadoop funcione em modo <em>cluster</em>. Para isso esse tutorial foi dividido em tr√™s tipos de configura√ß√µes, n√≥ <em>master</em>, <em>slaves</em> e para ambos.</p>

<p style="text-align: center;">
  <img src="/assets/images/programming-fire.gif" style="width: 50%;" />
</p>

<h3 id="para-o-n√≥-master">Para o n√≥ Master</h3>

<p>Para o n√≥ <em>master</em> basta editar o arquivo de configura√ß√£o etc/hadoop/hdfs-site.xml:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">~# vim hdfs-site.xml</code></pre></figure>

<p>No caso do n√≥ <em>master</em> iremos manter apenas a configura√ß√£o do <em>namenode</em>, removendo a propriedade do <em>datanode</em>:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"> <span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;description&gt;</span>Default block replication.
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time.
  <span class="nt">&lt;/description&gt;</span>
 <span class="nt">&lt;/property&gt;</span>

 <span class="nt">&lt;property&gt;</span>
   <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
   <span class="nt">&lt;value&gt;</span>file:/opt/bigdata/hadoop-2.8.1/hadoop_store/hdfs/namenode<span class="nt">&lt;/value&gt;</span>
 <span class="nt">&lt;/property&gt;</span></code></pre></figure>

<p>*ps: a tag <code class="language-html highlighter-rouge"><span class="nt">&lt;/property&gt;</span></code> deve ficar dentro de uma tag <code class="language-html highlighter-rouge"><span class="nt">&lt;configuration&gt;&lt;/configuration&gt;</span></code></p>

<p>Crie o arquivo com os endere√ßos IP‚Äôs das m√°quinas <em>slaves</em> do Hadoop no diret√≥rio etc/hadoop:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">~# <span class="nb">touch </span>slaves</code></pre></figure>

<p>Adicione o IP de todas as m√°quinas <em>slaves</em> em etc/hadoop/slaves:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">~# vim slaves</code></pre></figure>

<p>Adicione os endere√ßos IP‚Äôs ou <em>hostname</em> de cada uma das m√°quinas slaves:</p>

<figure class="highlight"><pre><code class="language-plaintext" data-lang="plaintext">IP_NODE_01
IP_NODE_02
IP_NODE_03
IP_NODE_04
IP_NODE_05
IP_NODE_0N
.
.
.</code></pre></figure>

<p>*ps: as informa√ß√µes deste arquivo devem ser apenas os IP‚Äôs ou Hostname das m√°quinas separadas por quebra de linha (enter)</p>

<h3 id="para-os-n√≥s-slaves">Para os n√≥s Slaves</h3>

<p>Para os n√≥s <em>slaves</em> iremos manter a configura√ß√£o do <em>datanode</em>, removendo a propriedade <em>namenode</em>:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;description&gt;</span>Default block replication.
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time.
  <span class="nt">&lt;/description&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>file:/opt/bigdata/hadoop-2.8.1/hadoop_store/hdfs/datanode<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span></code></pre></figure>

<p>*ps: a tag <code class="language-html highlighter-rouge"><span class="nt">&lt;/property&gt;</span></code> deve ficar dentro de uma tag <code class="language-html highlighter-rouge"><span class="nt">&lt;configuration&gt;&lt;/configuration&gt;</span></code></p>

<h3 id="para-ambos">Para ambos</h3>

<p>Para ambas as m√°quinas tanto <em>master</em> e <em>slave</em> iremos manter a configura√ß√£o do diret√≥rio tmp e iremos configurar o IP do n√≥ <em>master</em> (<em>Namenode</em>) com a propriedade fs.defaultFS:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>hadoop.tmp.dir<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>/opt/bigdata/hadoop-2.8.1/tmp<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;description&gt;</span>Temporary Directory.<span class="nt">&lt;/description&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>hdfs://IP_MASTER:9000<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;description&gt;</span>Use HDFS as file storage engine<span class="nt">&lt;/description&gt;</span>
<span class="nt">&lt;/property&gt;</span></code></pre></figure>

<p>*ps: a tag <code class="language-html highlighter-rouge"><span class="nt">&lt;/property&gt;</span></code> deve ficar dentro de uma tag <code class="language-html highlighter-rouge"><span class="nt">&lt;configuration&gt;&lt;/configuration&gt;</span></code></p>

<p>Edite e adicione as seguintes propriedades ao arquivo yarn-site.xml:</p>

<figure class="highlight"><pre><code class="language-xml" data-lang="xml"><span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.hostname<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>frontend<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;description&gt;</span>The hostname of the RM.<span class="nt">&lt;/description&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span>

<span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="nt">&lt;/value&gt;</span>
<span class="nt">&lt;/property&gt;</span></code></pre></figure>

<p>*ps: a tag <code class="language-html highlighter-rouge"><span class="nt">&lt;/property&gt;</span></code> deve ficar dentro de uma tag <code class="language-html highlighter-rouge"><span class="nt">&lt;configuration&gt;&lt;/configuration&gt;</span></code></p>

<h2 id="finaliza√ß√£o">Finaliza√ß√£o</h2>

<p>Ap√≥s as devidas configura√ß√µes, logue via ssh na m√°quina master e formate o <em>namenode</em>:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">~# hadoop namenode <span class="nt">-format</span></code></pre></figure>

<p>Inicie o Hadoop e verificar se ele est√° funcionando em modo cluster:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">~# start-dfs.sh <span class="o">&amp;&amp;</span> start-yarn.sh</code></pre></figure>

<p>Se tudo der certo, verifique os processos Hadoop que est√£o executando no n√≥ master:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">~# jps</code></pre></figure>

<p>Como voc√™ est√° acessando o n√≥ <em>master</em> deve aparecer para voc√™ apenas os seguintes processos:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">5417 Jps
4656 NameNode
5123 ResourceManager
4952 SecondaryNameNode</code></pre></figure>

<p>Acesse cada um dos n√≥s <em>slaves</em> e verifique os processos que Hadoop que est√£o executando:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">~# jps</code></pre></figure>

<p>Como voc√™ est√° acessando os n√≥s <em>slave</em> deve aparecer para voc√™ apenas os seguintes processos:</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">14372 Jps
13987 DataNode
14168 NodeManager</code></pre></figure>

<p>Se tudo estiver ok, pronto temos o Apache Hadoop configurado em modo <em>Multi Node</em> ;)</p>

<p style="text-align: center;">
  <img src="/assets/images/sheldon-fuck.gif" style="width: 60%;" />
</p>

<h2 id="disclaimer">Disclaimer</h2>

<p>Material desenvolvido durante o meu Mestrado no Instituto de Ci√™ncias Matem√°ticas e de Computa√ß√£o da Universidade de S√£o Paulo (<a href="http://icmc.usp.br/" target="_blank">ICMC-USP</a>). Al√©m disso, fa√ßo um agradecimento em especial ao Laborat√≥rio de Sistemas Distribu√≠dos e Programa√ß√£o Concorrente (<a href="http://lasdpc.icmc.usp.br/" target="_blank">LaSDPC</a>), o qual fa√ßo parte que me permitiu a cria√ß√£o deste material. Por fim, informo que √© permitido livremente a reprodu√ß√£o integral deste material desde que sejam feitas as devidas refer√™ncias ao autor ;)</p>

<h2 id="refer√™ncias">Refer√™ncias</h2>

<p>[1] Apache Foundation. Hadoop: <strong><em>Setting up a Single Node Cluster</em></strong>. Acessado em Agosto de 2016. Dispon√≠vel em: <a href="http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/SingleCluster.html">http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/SingleCluster.html</a></p>

<p>[2] Apache Foundation. Hadoop: <strong><em>Hadoop Cluster Setup</em></strong>. Acessado em Outubro de 2016. Dispon√≠vel em:
<a href="http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/ClusterSetup.html">http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/ClusterSetup.html</a></p>

<p>[3] Michael G. Noll. Running Hadoop on Ubuntu Linux (Multi-Node Cluster). Acessado em Outubro de 2016. Dispon√≠vel em: <a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/">http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/</a></p>
:ET