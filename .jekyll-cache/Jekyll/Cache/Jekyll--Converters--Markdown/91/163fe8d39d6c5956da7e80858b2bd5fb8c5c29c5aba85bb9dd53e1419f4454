I"f3<h2 id="instalação-do-apache-hadoop-28x-em-modo-multi-node">Instalação do Apache Hadoop 2.8.x em modo Multi Node</h2>

<p>Requisitos iniciais:</p>

<ul>
  <li>1) Tenha o Java 7+ instalado</li>
  <li>2) Realize a configuração em modo <a href="/config-hadoop-single-node/" target="_blank"><em>single node</em></a> para todas a máquinas desejadas</li>
  <li>3) Tenha o servidor SSH devidamente instalado e configurado</li>
  <li>4) Configure o SSH para o acesso sem senha com todos os endereços de IP das máquinas desejadas incluindo o <em>localhost</em></li>
</ul>

<p>*ps: Este tutorial foi testado com o sistema operacional Ubuntu 16.04 e 14.04. Caso deseje configurar em uma versão mais antiga, recente ou em outro SO, pequenas mudanças podem ocorrer nos procedimentos apresentados.</p>

<h3 id="tldr">TL;DR</h3>

<p>O projeto Apache Hadoop é um <em>software</em> de código aberto mantido pela Apache Foundation que tem como propósito fornecer uma implementação de código aberto do modelo de programação <em>MapReduce</em> de forma confiável e escalável. O Hadoop é projetado para ampliar o processamento de um único servidor em milhares de máquinas, onde cada uma das máquinas oferecem poder de processamento e armazenamento local. Esta ferramenta é utilizada para processamento em <em>batch</em> de grandes volumes de dados (<em>Big Data</em>). Atualmente, o Apache Hadoop é uma das ferramentas mais conhecidas para processamento distribuído, mas existem outras ferramentas similares que se integram ao Hadoop, como o <strong>Apache Spark</strong>, <strong>Apache Storm</strong> e dentre outros.</p>

<p>*para mais informações a respeito do Apache Hadoop acessem o site <a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></p>

<h3 id="lets-get-started">Let’s get started</h3>

<p>Neste tutorial você irá aprender a configurar o Apache Hadoop no modo <em>Multi Node</em>. Montando um ambiente capaz de executar seus primeiros <em>scripts</em> em <em>MapReduce</em>.</p>

<p>Primeiramente configure todas as máquinas que deseja montar um cluster Hadoop no modo <em>single node</em>. Para configurar basta seguir as instruções disponíveis no seguinte <a href="/config-hadoop-single-node">link</a>.</p>

<p>Outro ponto importante é a configuração do ssh sem senha entre todas máquinas que você pretende montar o cluster, o que inclui ela mesma (<em>localhost</em>). Para realizar essa tarefa basta seguir as instruções do tutorial disponibilizado no portal <a href="https://www.vivaolinux.com.br/dica/SSH-sem-senha/">Viva o Linux</a>.</p>

<p>Após realizada essa primeira etapa vamos fazer as devidas modificações para que o Hadoop funcione em modo <em>cluster</em>. Para isso esse tutorial foi dividido em três tipos de configurações, nó <em>master</em>, <em>slaves</em> e para ambos.</p>

<p style="text-align: center;">
  <img src="/assets/images/programming-fire.gif" style="width: 50%;" />
</p>

<h3 id="para-o-nó-master">Para o nó Master</h3>

<p>Para o nó <em>master</em> basta editar o arquivo de configuração etc/hadoop/hdfs-site.xml:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~# vim hdfs-site.xml
</code></pre></div></div>

<p>No caso do nó <em>master</em> iremos manter apenas a configuração do <em>namenode</em>, removendo a propriedade do <em>datanode</em>:</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;description&gt;</span>Default block replication.
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time.
  <span class="nt">&lt;/description&gt;</span>
 <span class="nt">&lt;/property&gt;</span>

 <span class="nt">&lt;property&gt;</span>
   <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
   <span class="nt">&lt;value&gt;</span>file:/opt/bigdata/hadoop-2.8.1/hadoop_store/hdfs/namenode<span class="nt">&lt;/value&gt;</span>
 <span class="nt">&lt;/property&gt;</span>
</code></pre></div></div>

<p>*ps: a tag <code class="highlighter-rouge">&lt;/property&gt;</code> deve ficar dentro de uma tag <code class="highlighter-rouge">&lt;configuration&gt;&lt;/configuration&gt;</code></p>

<p>Vamos criar o arquivo com os endereços IP’s das máquinas <em>slaves</em> do Hadoop no diretório etc/hadoop:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~# <span class="nb">touch </span>slaves
</code></pre></div></div>

<p>Vamos adicionar o IP de todas as máquinas <em>slaves</em> em etc/hadoop/slaves:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~# vim slaves
</code></pre></div></div>

<p>Adicione os endereços IP’s ou <em>hostname</em> de cada uma das máquinas slaves:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>IP_NODE_01
IP_NODE_02
IP_NODE_03
IP_NODE_04
IP_NODE_05
IP_NODE_0N
.
.
.
</code></pre></div></div>

<p>*ps: as informações deste arquivo devem ser apenas os IP’s ou Hostname das máquinas separadas por quebra de linha (enter)</p>

<h3 id="para-os-nós-slaves">Para os nós Slaves</h3>

<p>Para os nós <em>slaves</em> iremos manter a configuração do <em>datanode</em>, removendo a propriedade <em>namenode</em>:</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;description&gt;</span>Default block replication.
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time.
  <span class="nt">&lt;/description&gt;</span>
 <span class="nt">&lt;/property&gt;</span>
 
 <span class="nt">&lt;property&gt;</span>
   <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir<span class="nt">&lt;/name&gt;</span>
   <span class="nt">&lt;value&gt;</span>file:/opt/bigdata/hadoop-2.8.1/hadoop_store/hdfs/datanode<span class="nt">&lt;/value&gt;</span>
 <span class="nt">&lt;/property&gt;</span>
</code></pre></div></div>

<p>*ps: a tag <code class="highlighter-rouge">&lt;/property&gt;</code> deve ficar dentro de uma tag <code class="highlighter-rouge">&lt;configuration&gt;&lt;/configuration&gt;</code></p>

<h3 id="para-ambos">Para ambos</h3>

<p>Para ambas as máquinas tanto <em>master</em> e <em>slave</em> iremos manter a configuração do diretório tmp e iremos configurar o IP do nó <em>master</em> (<em>Namenode</em>) com a propriedade fs.defaultFS:</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>hadoop.tmp.dir<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>/opt/bigdata/hadoop-2.8.1/tmp<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;description&gt;</span>Temporary Directory.<span class="nt">&lt;/description&gt;</span>
 <span class="nt">&lt;/property&gt;</span>

 <span class="nt">&lt;property&gt;</span>
  <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
  <span class="nt">&lt;value&gt;</span>hdfs://IP_MASTER:9000<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;description&gt;</span>Use HDFS as file storage engine<span class="nt">&lt;/description&gt;</span>
 <span class="nt">&lt;/property&gt;</span>
</code></pre></div></div>

<p>*ps: a tag <code class="highlighter-rouge">&lt;/property&gt;</code> deve ficar dentro de uma tag <code class="highlighter-rouge">&lt;configuration&gt;&lt;/configuration&gt;</code></p>

<p>Vamos editar e adicionar as seguintes propriedades ao arquivo yarn-site.xml:</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nt">&lt;property&gt;</span>
          <span class="nt">&lt;name&gt;</span>yarn.resourcemanager.hostname<span class="nt">&lt;/name&gt;</span>
          <span class="nt">&lt;value&gt;</span>frontend<span class="nt">&lt;/value&gt;</span>
          <span class="nt">&lt;description&gt;</span>The hostname of the RM.<span class="nt">&lt;/description&gt;</span>
  <span class="nt">&lt;/property&gt;</span>

  <span class="nt">&lt;property&gt;</span>
           <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
           <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>

  <span class="nt">&lt;property&gt;</span>
           <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="nt">&lt;/name&gt;</span>
           <span class="nt">&lt;value&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="nt">&lt;/value&gt;</span>
  <span class="nt">&lt;/property&gt;</span>
</code></pre></div></div>

<p>*ps: a tag <code class="highlighter-rouge">&lt;/property&gt;</code> deve ficar dentro de uma tag <code class="highlighter-rouge">&lt;configuration&gt;&lt;/configuration&gt;</code></p>

<h2 id="finalização">Finalização</h2>

<p>Após as devidas configurações, logue via ssh na máquina master e formate o <em>namenode</em>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~# hadoop namenode <span class="nt">-format</span>
</code></pre></div></div>

<p>Agora vamos iniciar o Hadoop e verificar se ele está funcionando em modo cluster:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~# start-dfs.sh <span class="o">&amp;&amp;</span> start-yarn.sh
</code></pre></div></div>

<p>Se tudo der certo, verifique os processos Hadoop que estão executando no nó master:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~# jps
</code></pre></div></div>

<p>Como você está acessando o nó <em>master</em> deve aparecer para você apenas os seguintes processos:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>5417 Jps
4656 NameNode
5123 ResourceManager
4952 SecondaryNameNode
</code></pre></div></div>

<p>Acesse cada um dos nós <em>slaves</em> e verifique os processos que Hadoop que estão executando:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>~# jps
</code></pre></div></div>

<p>Como você está acessando os nós <em>slave</em> deve aparecer para você apenas os seguintes processos:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>14372 Jps
13987 DataNode
14168 NodeManager
</code></pre></div></div>

<p>Se tudo estiver ok, pronto temos o Apache Hadoop configurado em modo <em>Multi Node</em> ;)</p>

<p style="text-align: center;">
  <img src="/assets/images/sheldon-fuck.gif" style="width: 60%;" />
</p>

<h2 id="disclaimer">Disclaimer</h2>

<p>Material desenvolvido durante o meu Mestrado no Instituto de Ciências Matemáticas e de Computação da Universidade de São Paulo (<a href="http://icmc.usp.br/" target="_blank">ICMC-USP</a>). Além disso, faço um agradecimento em especial ao Laboratório de Sistemas Distribuídos e Programação Concorrente (<a href="http://lasdpc.icmc.usp.br/" target="_blank">LaSDPC</a>), o qual faço parte que me permitiu a criação deste material. Por fim, informo que é permitido livremente a reprodução integral deste material desde que sejam feitas as devidas referências ao autor ;)</p>

<h2 id="referências">Referências</h2>

<p>[1] Apache Foundation. Hadoop: <strong><em>Setting up a Single Node Cluster</em></strong>. Acessado em Agosto de 2016. Disponível em: <a href="http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/SingleCluster.html">http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/SingleCluster.html</a></p>

<p>[2] Apache Foundation. Hadoop: <strong><em>Hadoop Cluster Setup</em></strong>. Acessado em Outubro de 2016. Disponível em:
<a href="http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/ClusterSetup.html">http://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/ClusterSetup.html</a></p>

<p>[3] Michael G. Noll. Running Hadoop on Ubuntu Linux (Multi-Node Cluster). Acessado em Outubro de 2016. Disponível em: <a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/">http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/</a></p>
:ET